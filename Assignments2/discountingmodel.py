# -*- coding: utf-8 -*-
"""DiscountingModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BYK-vNJc0IGBM81yu9AKvmP2V29dUn1m
"""

!pip install nltk

import nltk
nltk.download('popular')

from nltk.tokenize import sent_tokenize, word_tokenize

#with open('/content/drive/My Drive/400lineCorpus.txt') as f:
  #text = f.read()

#with open('/content/drive/My Drive/shortestCorpus.txt') as f:
  #text = f.read()

with open('/content/drive/My Drive/shortCorpus.txt') as f:
  text = f.read()

#with open('/content/drive/My Drive/1000lineCorpus.txt') as f:
  #text = f.read()

sentenceTokens = sent_tokenize(text)

print(len(sentenceTokens))

import random

random.shuffle(sentenceTokens)

noOfSen = len(sentenceTokens)
partIndex = int((noOfSen*9)/10)

trainAndDev = sentenceTokens[:partIndex]
test = sentenceTokens[partIndex:]

noOfSenTandD = len(trainAndDev)
partITandD = int((noOfSenTandD*9)/10)

import itertools
import operator
import collections
from collections import Counter
import matplotlib.pyplot as plt
from nltk.util import ngrams
from scipy.stats import binom 
import math
from decimal import *

"""Function For Padding Start and End"""

start = "S123T S123T "
end = " E321D"

def padStartandEnd(listOfSen):
  noOfSen = len(listOfSen)
  for i in range(noOfSen):
    listOfSen[i] = start + listOfSen[i] + end
  return listOfSen

"""Function For Removing Unwanted Tokens"""

def remove_values_from_list(the_list, val):
   return [value for value in the_list if value != val]

"""Function For Tokenizing All Sentences"""

def tokenizeAllSentences(listOfSen):
  allWordTokens = []
  for sen in listOfSen:
    allWordTokens.extend(word_tokenize(sen))
  return allWordTokens

"""Function For Replacing tokens in sentence which are not present in Vocab or have Less Frequency"""

def replacelessfreq(listOfTokensinSen,freqWordsTraining):
  for i in range(len(listOfTokensinSen)):
    if (listOfTokensinSen[i] in freqWordsTraining):
        if (freqWordsTraining[listOfTokensinSen[i]]<10):
            #print(listOfTokensinSen[i]," ",freqWordsTraining[listOfTokensinSen[i]])
            listOfTokensinSen[i] = 'U345K'
    else:
      #print(listOfTokensinSen[i])
      if (listOfTokensinSen[i]!='S123T' and listOfTokensinSen[i]!='E321D'):
          listOfTokensinSen[i] = 'U345K'
  return listOfTokensinSen

"""Function For Replacing tokens in all sentence and return list of tokens for all sentences"""

def replaceAndReturnTokenlist(listOfSen,freqWordsTraining):
  replacedTokensListofAllSen = []
  for sen in listOfSen:
    #temp = remove_values_from_list(word_tokenize(sen), '.')
    listOfTokensinSen = word_tokenize(sen)
    listOfTokensinSen = replacelessfreq(listOfTokensinSen,freqWordsTraining)
    replacedTokensListofAllSen.append(listOfTokensinSen)
  return replacedTokensListofAllSen

"""Total no. of words (they may be same)"""

def totalWords(freqDict):
  totalfreq = 0;
  for val in freqDict:
    totalfreq += freqDict[val]
  return totalfreq

"""Discounting Function

Function for calculating all possible bigram probab
"""

def calculateBigramDiscount(freqUnigram,freqBigram,totalFreqUnigram,beta):
  bigramProbab = {}
  for v in freqUnigram:
    alpha_v =0
    sum_freq_vw =0
    sum_probab_vw =0

    for w in freqUnigram:
      if ((v,w) in freqBigram):
        bigramProbab[(v,w)] = (freqBigram[(v,w)]-beta)/freqUnigram[v]
        sum_probab_vw += bigramProbab[(v,w)]
        sum_freq_vw += freqUnigram[w]

    alpha_v = 1-sum_probab_vw
    sum_freq_vnotw = totalFreqUnigram - sum_freq_vw

    for w in freqUnigram:
      if ((v,w) not in freqBigram):
        bigramProbab[(v,w)] = alpha_v*(freqUnigram[w]/sum_freq_vnotw)

  return bigramProbab

"""Function for calculating all possible trigram probab"""

def calculateTrigramDiscount(bigramProbab,freqUnigram,freqBigram,freqTrigram,beta):
  trigramProbab = {}
  for u in freqUnigram:
    for v in freqUnigram:
      alpha_uv = 0
      sum_freq_uvw =0
      sum_probab_uvw =0

      for w in freqUnigram:
        if ((u,v,w) in freqTrigram):
          trigramProbab[(u,v,w)] = (freqTrigram[(u,v,w)]-beta)/freqBigram[(u,v)]
          sum_probab_uvw += trigramProbab[(u,v,w)]
          sum_freq_uvw += bigramProbab[(v,w)]

      alpha_uv = 1-sum_probab_uvw
      sum_freq_uvnotw = 1-sum_freq_uvw

      for w in freqUnigram:
        if ((u,v,w) not in freqTrigram):
          trigramProbab[(u,v,w)] = alpha_uv*(bigramProbab[(v,w)]/sum_freq_uvnotw)
  
  return trigramProbab

"""Calculates Particular Trigram Probab if Tri not Present"""

def calculateParticularTri(elm,bigramProbab,freqUnigram,freqBigram,freqTrigram,beta):
  u = elm[0]
  v = elm[1]
  w_orig = elm[2]

  alpha_uv = 0
  sum_freq_uvw =0
  sum_probab_uvw =0

  for w in freqUnigram:
    if ((u,v,w) in freqTrigram):
      temp = (freqTrigram[(u,v,w)]-beta)/freqBigram[(u,v)]
      sum_probab_uvw += temp
      sum_freq_uvw += bigramProbab[(v,w)]

  alpha_uv = 1-sum_probab_uvw
  sum_freq_uvnotw = 1-sum_freq_uvw

  temp = alpha_uv*(bigramProbab[(v,w_orig)]/sum_freq_uvnotw)
  return temp

"""Function for Discounting Probability of a Sentence"""

def probabOfSentenceDiscount(trigramsListSen,bigramProbab,freqUnigram,freqBigram,freqTrigram,beta):
  probabSen =0
  #print("entered")
  for elm in trigramsListSen:
    #print("entered")
    u = elm[0]
    v = elm[1]
    w = elm[2]
    if (u,v,w) in freqTrigram:
      temp = (freqTrigram[(u,v,w)]-beta)/freqBigram[(u,v)]
      probabSen += math.log(temp,2)
    else:
      temp = calculateParticularTri(elm,bigramProbab,freqUnigram,freqBigram,freqTrigram,beta)
      probabSen += math.log(temp,2)
  
  return probabSen

"""Laplace Smoothing Function for Sentence"""

def probabOfSentenceLaplace(trigramsListSen,freqBigram,freqTrigram,sizeOfVocabulary):
  probabSen =0
  for elm in trigramsListSen:
    temp =0;
    u = elm[0]
    v = elm[1]
    w = elm[2]
    #print(u," ",v," ",w)
    if (u,v,w) in freqTrigram:
      temp = (freqTrigram[(u,v,w)]+1)/(freqBigram[(u,v)]+sizeOfVocabulary)
    else:
      if (u,v) in freqBigram:
        temp = 1/(freqBigram[(u,v)]+sizeOfVocabulary)
      else:
        temp = 1/(sizeOfVocabulary)
    probabSen += math.log(temp,2)
  return probabSen

"""Perplexity Function"""

def calculatePerplexity(M,totalLogProbAllSen):
  l = (totalLogProbAllSen/M)
  return pow(2,-1*l)

"""Function for Analysing by randomly choosing set of train and dev"""

def createTrainingAndDevAndTestforAllBeta():
  random.shuffle(trainAndDev)

  train = trainAndDev[:partITandD]
  dev = trainAndDev[partITandD:]

  print("length of train: ",len(train))
  print("length of dev: ",len(dev))

  train = padStartandEnd(train)
  print("")
  print("padding done in training")
  #train[:10]

  wordTokensTrain = tokenizeAllSentences(train)
  freqWords = dict(Counter(wordTokensTrain))

  replacedTokenListAllSenTrain = replaceAndReturnTokenlist(train,freqWords)
  print("")
  print("lower frequency words replaced in train")
  #replacedTokenListAllSenTrain[:2]

  unigrams = []
  for sen in replacedTokenListAllSenTrain:
    unigrams.extend(sen)
  print("")
  print("unigrams extracted")
  #unigrams[:10]

  freqUnigram = dict(Counter(unigrams))

  freqList = list(freqUnigram.values())
  bins = [1,2,3,4,5,6,7,8,9,10,15,20,25,30,35,40,50]
  print("")
  print("Verifying Lower frequency words Removed in train")
  #plt.hist(freqList,bins=bins,edgecolor='black')

  bigrams = []
  for sen in replacedTokenListAllSenTrain:
    bigrams.extend(list(ngrams(sen,2)))
  print("")
  print("bigrams extracted")
  #bigrams[:10]

  freqBigram = dict(Counter(bigrams))

  trigrams = []
  for sen in replacedTokenListAllSenTrain:
    trigrams.extend(list(ngrams(sen,3)))
  print("")
  print("trigrams extracted")
  #trigrams[:10]

  freqTrigram = dict(Counter(trigrams))
  print("")
  print("Number of distinct words remain: ",len(freqUnigram))
  totalFreqUnigram = totalWords(freqUnigram)
  print("Total number of words: ",totalFreqUnigram)

  dev = padStartandEnd(dev)
  print("")
  print("padding done in dev")
  #dev[:10]

  replacedTokenListAllSenDev = replaceAndReturnTokenlist(dev,freqWords)
  print("")
  print("lower frequency and out of vocab words replaced in dev")
  #replacedTokenListAllSenTrain[:2]

  betas  = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]
  for beta in betas:
    bigramProbab = calculateBigramDiscount(freqUnigram,freqBigram,totalFreqUnigram,beta)

    M = 0
    totalLogProbAllSen =0
    for sen in replacedTokenListAllSenDev:
      trigramsListSen = list(ngrams(sen,3))
      M += len(trigramsListSen)
      pOfSen = probabOfSentenceDiscount(trigramsListSen,bigramProbab,freqUnigram,freqBigram,freqTrigram,beta)
      #print(pOfSen)
      totalLogProbAllSen += pOfSen

    print("")
    print("For beta = ",beta)

    print("M = ",M)

    lgLikelihood = totalLogProbAllSen
    print("log likelihood = ",lgLikelihood)

    perplexity = calculatePerplexity(M,totalLogProbAllSen)
    print("Perplexity = ",perplexity)

"""Analysis on 1st Set of Training and Dev"""

createTrainingAndDevAndTestforAllBeta()

"""Analysis on 2nd Set of Training and Dev"""

createTrainingAndDevAndTestforAllBeta()

"""Analysis on 3rd Set of Training and Dev"""

createTrainingAndDevAndTestforAllBeta()

"""Analysis on 4th Set of Training and Dev"""

createTrainingAndDevAndTestforAllBeta()

"""Analysis on 5th Set of Training and Dev"""

createTrainingAndDevAndTestforAllBeta()

"""**Finally Analysing on Test Data taking best Beta**"""

beta =0.7

train = trainAndDev[:partITandD]

print(len(train))
print(len(test))

train = padStartandEnd(train)
train[:10]

wordTokensTrain = tokenizeAllSentences(train)
freqWords = dict(Counter(wordTokensTrain))

replacedTokenListAllSenTrain = replaceAndReturnTokenlist(train,freqWords)
replacedTokenListAllSenTrain[:10]

"""N-Grams Frequency Calculation for Training Set"""

unigrams = []
for sen in replacedTokenListAllSenTrain:
  unigrams.extend(sen)

freqUnigram = dict(Counter(unigrams))

unigrams[:20]

"""Verifying No. Unigram have less frequency now"""

freqList = list(freqUnigram.values())
bins = [1,2,3,4,5,6,7,8,9,10,15,20,25,30,35,40,50]
plt.hist(freqList,bins=bins,edgecolor='black')

bigrams = []
for sen in replacedTokenListAllSenTrain:
  bigrams.extend(list(ngrams(sen,2)))

freqBigram = dict(Counter(bigrams))

bigrams[:20]

trigrams = []
for sen in replacedTokenListAllSenTrain:
  trigrams.extend(list(ngrams(sen,3)))

freqTrigram = dict(Counter(trigrams))

trigrams[:20]

print(len(freqUnigram))

totalFreqUnigram = totalWords(freqUnigram)

print(totalFreqUnigram)

bigramProbab = calculateBigramDiscount(freqUnigram,freqBigram,totalFreqUnigram,beta)

"""Test Set"""

test = padStartandEnd(test)

test[:10]

replacedTokenListAllSenTest = replaceAndReturnTokenlist(test,freqWords)

M = 0
totalLogProbAllSen =0
for sen in replacedTokenListAllSenTest:
  trigramsListSen = list(ngrams(sen,3))
  M += len(trigramsListSen)
  pOfSen = probabOfSentenceDiscount(trigramsListSen,bigramProbab,freqUnigram,freqBigram,freqTrigram,beta)
  #print(pOfSen)
  totalLogProbAllSen += pOfSen

print(M)

lgLikelihood = totalLogProbAllSen
print(lgLikelihood)

perplexity = calculatePerplexity(M,totalLogProbAllSen)
print(perplexity)

"""Applying Laplace"""

M =0
totalLogProbAllSen =0
for sen in replacedTokenListAllSenTest:
  trigramsListSen = list(ngrams(sen,3))
  M += len(trigramsListSen)
  pOfSen = probabOfSentenceLaplace(trigramsListSen,freqBigram,freqTrigram,len(freqUnigram))
  #print(pOfSen)
  totalLogProbAllSen += pOfSen

print(M)

lgLikelihood = totalLogProbAllSen
print(lgLikelihood)

perplexity = calculatePerplexity(M,totalLogProbAllSen)
print(perplexity)